{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffPM9vMVQXpn",
        "outputId": "dffece1e-92e9-427e-e6b9-ea4cafdd8fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded dataset with 432 rows and columns: ['Class', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
            "✅ Loaded 1 rules from M3.txt\n",
            "Accuracy  : 0.8953488372093024\n",
            "Precision : 0.8953488372093024\n",
            "Recall    : 0.8955627705627706\n",
            "F1 Score  : 0.8953346855983773\n",
            "Execution Time (seconds): 0.18248796463012695\n",
            "Rule [0, 0, 0, 5, 0, 1, 0, 2] → Accuracy = 0.8953\n",
            "\n",
            "✅ Results written to rule_accuracy.txt\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ---------- Step 1: CA evolution ----------\n",
        "def evolve_CA(PS, Rule, d, n, left, right):\n",
        "    \"\"\"Evolves the given CA state once and returns the next state.\"\"\"\n",
        "    m = left + right + 1\n",
        "    NS = [0] * n\n",
        "    for i in range(n):\n",
        "        RMT = 0\n",
        "        rng = m - 1\n",
        "        for j in range(i - left, i + right + 1):\n",
        "            RMT += int((d ** rng) * PS[(n + j) % n])\n",
        "            rng -= 1\n",
        "        NS[i] = Rule[RMT]\n",
        "    return NS\n",
        "\n",
        "\n",
        "# ---------- Step 2: Cycle finding ----------\n",
        "def find_cycle(start_state, Rule, d, n, left, right):\n",
        "    \"\"\"Return the cycle (list of states) reached from the starting state.\"\"\"\n",
        "    seen = {}\n",
        "    PS = start_state[:]\n",
        "    step = 0\n",
        "    while True:\n",
        "        state_tuple = tuple(PS)\n",
        "        if state_tuple in seen:\n",
        "            start_idx = seen[state_tuple]\n",
        "            cycle = list(seen.keys())[start_idx:]\n",
        "            return cycle\n",
        "        seen[state_tuple] = step\n",
        "        step += 1\n",
        "        PS = evolve_CA(PS, Rule, d, n, left, right)\n",
        "\n",
        "\n",
        "# ---------- Step 3: Canonical cycle ----------\n",
        "def canonical_cycle_key(cycle):\n",
        "    \"\"\"Convert a cycle (list of states) into a unique rotation-invariant string key.\"\"\"\n",
        "    strs = [\"\".join(map(str, s)) for s in cycle]\n",
        "    rotations = [\"-\".join(strs[i:] + strs[:i]) for i in range(len(strs))]\n",
        "    return min(rotations)\n",
        "\n",
        "\n",
        "# ---------- Step 4: Rule generation ----------\n",
        "def generate_rule(params, d):\n",
        "    left = right = 1\n",
        "    m = left + right + 1\n",
        "    Rule = []\n",
        "    for x in range(d):\n",
        "        for y in range(d):\n",
        "            for z in range(d):\n",
        "                Rule.append((params[0]*x*y*z + params[1]*x*y + params[2]*x*z +\n",
        "                             params[3]*y*z + params[4]*x + params[5]*y +\n",
        "                             params[6]*z + params[7]) % d)\n",
        "    return Rule\n",
        "\n",
        "\n",
        "def compute_accuracy(df, Rule, d=10, left=1, right=1):\n",
        "    \"\"\"Train-test split, classify, and compute accuracy.\n",
        "    Uses ALL attribute columns (assumes last column is the class).\n",
        "    Pads each attribute to the same global max length (leading zeros),\n",
        "    concatenates them and treats the concatenation as the CA configuration.\n",
        "    \"\"\"\n",
        "    # --- Train/test split ---\n",
        "    train_df = df.sample(frac=0.8, random_state=42)\n",
        "    test_df = df.drop(train_df.index)\n",
        "\n",
        "    # # --- Identify attribute columns and class column (assume class is last column) ---\n",
        "    # attr_cols = list(df.columns[:-1])\n",
        "    # class_col = df.columns[-1]\n",
        "\n",
        "    # --- Identify attribute columns and class column (use column named \"Class\") ---\n",
        "    class_col = \"Class\"\n",
        "    attr_cols = [col for col in df.columns if col != class_col]\n",
        "\n",
        "\n",
        "    # --- Helper: keep only digits from string (fallback for messy inputs) ---\n",
        "    def digits_only(x):\n",
        "        s = str(x)\n",
        "        filtered = \"\".join(ch for ch in s if ch.isdigit())\n",
        "        return filtered if filtered != \"\" else \"0\"\n",
        "\n",
        "    # --- Compute global max length across all attributes (as digit-strings) ---\n",
        "    max_len = 0\n",
        "    for val in df[attr_cols].values.flatten():\n",
        "        ln = len(digits_only(val))\n",
        "        if ln > max_len:\n",
        "            max_len = ln\n",
        "    if max_len == 0:\n",
        "        max_len = 1  # safety\n",
        "\n",
        "    # --- Training phase ---\n",
        "    cycle_map = {}\n",
        "    for _, row in train_df.iterrows():\n",
        "        # pad every attribute to global max_len and concatenate in column order\n",
        "        parts = []\n",
        "        for c in attr_cols:\n",
        "            s = digits_only(row[c])\n",
        "            parts.append(s.zfill(max_len))\n",
        "        concat = \"\".join(parts)\n",
        "\n",
        "        PS = [int(ch) for ch in concat]          # initial configuration\n",
        "        n = len(PS)\n",
        "        label = row[class_col]\n",
        "\n",
        "        cycle = find_cycle(PS, Rule, d, n, left, right)\n",
        "        cycle_key = canonical_cycle_key(cycle)\n",
        "        cycle_map.setdefault(cycle_key, []).append(label)\n",
        "\n",
        "    # --- Assign majority label per cycle ---\n",
        "    cycle_labels = {c: max(set(labels), key=labels.count) for c, labels in cycle_map.items()}\n",
        "\n",
        "    # Print cycle→label mapping (you asked for this)\n",
        "    # print(\"\\nCycle → Label mapping:\")\n",
        "    # for c, lbl in cycle_labels.items():\n",
        "    #     print(f\"Cycle: {c} → Label: {lbl}\")\n",
        "\n",
        "    # # --- Testing phase ---\n",
        "    # correct = 0\n",
        "    # for _, row in test_df.iterrows():\n",
        "    #     parts = []\n",
        "    #     for c in attr_cols:\n",
        "    #         s = digits_only(row[c])\n",
        "    #         parts.append(s.zfill(max_len))\n",
        "    #     concat = \"\".join(parts)\n",
        "    #     PS = [int(ch) for ch in concat]\n",
        "    #     n = len(PS)\n",
        "    #     true_label = row[class_col]\n",
        "\n",
        "    #     test_cycle = find_cycle(PS, Rule, d, n, left, right)\n",
        "    #     test_key = canonical_cycle_key(test_cycle)\n",
        "\n",
        "    #     # --- Check if cycle known ---\n",
        "    #     if test_key in cycle_labels:\n",
        "    #         pred = cycle_labels[test_key]\n",
        "    #     else:\n",
        "    #         # Fallback: nearest median rule (as in your original code)\n",
        "    #         cycle_medians = {}\n",
        "    #         for c in cycle_labels.keys():\n",
        "    #             states = c.split(\"-\")\n",
        "    #             values = [int(s) for s in states]\n",
        "    #             median_val = sorted(values)[len(values)//2]\n",
        "    #             cycle_medians[c] = median_val\n",
        "\n",
        "    #         test_states = test_key.split(\"-\")\n",
        "    #         test_values = [int(s) for s in test_states]\n",
        "    #         test_median = sorted(test_values)[len(test_values)//2]\n",
        "\n",
        "    #         nearest_cycle = min(cycle_medians.keys(), key=lambda c: abs(cycle_medians[c] - test_median))\n",
        "    #         pred = cycle_labels[nearest_cycle]\n",
        "\n",
        "    #     if pred == true_label:\n",
        "    #         correct += 1\n",
        "\n",
        "    # accuracy = correct / len(test_df) if len(test_df) > 0 else 0\n",
        "    # return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "    # --- Testing phase ---\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for _, row in test_df.iterrows():\n",
        "        parts = []\n",
        "        for c in attr_cols:\n",
        "            s = digits_only(row[c])\n",
        "            parts.append(s.zfill(max_len))\n",
        "        concat = \"\".join(parts)\n",
        "        PS = [int(ch) for ch in concat]\n",
        "        n = len(PS)\n",
        "        true_label = row[class_col]\n",
        "\n",
        "        test_cycle = find_cycle(PS, Rule, d, n, left, right)\n",
        "        test_key = canonical_cycle_key(test_cycle)\n",
        "\n",
        "        # --- Prediction ---\n",
        "        if test_key in cycle_labels:\n",
        "            pred = cycle_labels[test_key]\n",
        "        else:\n",
        "            # Fallback using nearest median\n",
        "            cycle_medians = {}\n",
        "            for c in cycle_labels.keys():\n",
        "                states = c.split(\"-\")\n",
        "                values = [int(s) for s in states]\n",
        "                median_val = sorted(values)[len(values)//2]\n",
        "                cycle_medians[c] = median_val\n",
        "\n",
        "            test_states = test_key.split(\"-\")\n",
        "            test_values = [int(s) for s in test_states]\n",
        "            test_median = sorted(test_values)[len(test_values)//2]\n",
        "\n",
        "            nearest_cycle = min(cycle_medians.keys(), key=lambda c: abs(cycle_medians[c] - test_median))\n",
        "            pred = cycle_labels[nearest_cycle]\n",
        "\n",
        "        y_true.append(true_label)\n",
        "        y_pred.append(pred)\n",
        "\n",
        "    # --- Compute metrics ---\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    # ✅ Print inside the function (NOT returned)\n",
        "    print(\"Accuracy  :\", accuracy)\n",
        "    print(\"Precision :\", precision)\n",
        "    print(\"Recall    :\", recall)\n",
        "    print(\"F1 Score  :\", f1)\n",
        "\n",
        "    # ✅ Keep your original return (accuracy only)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "# ---------- Step 6: Main ----------\n",
        "def main():\n",
        "    # === Load dataset (.csv) ===\n",
        "    dataset_path = \"monks-3-new.csv\"   # <-- change this to your file\n",
        "    df = pd.read_csv(dataset_path)\n",
        "    print(f\"✅ Loaded dataset with {len(df)} rows and columns: {list(df.columns)}\")\n",
        "    # df_expanded = df.sample(n=1000, replace=True, random_state=42)\n",
        "    # print(len(df_expanded))\n",
        "    # === Load rule parameters from file ===\n",
        "    param_file = \"M3.txt\"\n",
        "    with open(param_file, \"r\") as f:\n",
        "        param_lines = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    param_sets = [[int(x) for x in line.split()] for line in param_lines]\n",
        "    print(f\"✅ Loaded {len(param_sets)} rules from {param_file}\")\n",
        "\n",
        "    import random\n",
        "\n",
        "    # Assuming param_sets is already defined\n",
        "    # sampled_params = random.sample(param_sets, 1000)\n",
        "\n",
        "\n",
        "\n",
        "    # === Evaluate each rule ===\n",
        "    results = []\n",
        "    #for params in param_sets:\n",
        "    for params in param_sets:\n",
        "        Rule = generate_rule(params, d=10)\n",
        "        import time\n",
        "\n",
        "        start = time.time()\n",
        "        acc = compute_accuracy(df, Rule, d=10)\n",
        "        end = time.time()\n",
        "\n",
        "        print(\"Execution Time (seconds):\", end - start)\n",
        "\n",
        "        # acc = compute_accuracy(df_expanded, Rule, d=10)\n",
        "        results.append((params, acc))\n",
        "        print(f\"Rule {params} → Accuracy = {acc:.4f}\")\n",
        "        with open(\"Accuracy.txt\", \"a\") as f:\n",
        "          f.write(\" \".join(map(str, params)) + f\"  Accuracy={acc:.4f}\\n\")\n",
        "\n",
        "    # === Write results to file ===\n",
        "    # with open(\"rule_accuracy.txt\", \"w\") as f:\n",
        "    #     for params, acc in results:\n",
        "    #         f.write(\" \".join(map(str, params)) + f\"  Accuracy={acc:.4f}\\n\")\n",
        "\n",
        "    print(\"\\n✅ Results written to rule_accuracy.txt\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwP2oHmRAy_G"
      },
      "source": [
        "Performance Comparison with Existing ML Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTMedWg7-xU2",
        "outputId": "35e6f003-0534-4856-d32c-bda48c447b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*************************SVM (Linear)************************************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.69      0.93      0.80        44\n",
            "           2       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.66        62\n",
            "   macro avg       0.35      0.47      0.40        62\n",
            "weighted avg       0.49      0.66      0.56        62\n",
            "\n",
            "Accuracy: 0.661\n",
            "Precision: 0.695\n",
            "Recall: 0.932\n",
            "F1 Score: 0.796\n",
            "*************************MultinomialNB************************************\n",
            "Accuracy: 0.710\n",
            "Precision: 0.741\n",
            "Recall: 0.909\n",
            "F1 Score: 0.816\n",
            "***************************DecisionTreeClassifier*********************\n",
            "[[34 10]\n",
            " [12  6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.74      0.77      0.76        44\n",
            "           2       0.38      0.33      0.35        18\n",
            "\n",
            "    accuracy                           0.65        62\n",
            "   macro avg       0.56      0.55      0.55        62\n",
            "weighted avg       0.63      0.65      0.64        62\n",
            "\n",
            "Accuracy: 0.645\n",
            "Precision: 0.739\n",
            "Recall: 0.773\n",
            "F1 Score: 0.756\n",
            "**********************LinearRegression*********************\n",
            "[[44  0]\n",
            " [18  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.71      1.00      0.83        44\n",
            "           2       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.71        62\n",
            "   macro avg       0.35      0.50      0.42        62\n",
            "weighted avg       0.50      0.71      0.59        62\n",
            "\n",
            "Accuracy: 0.710\n",
            "Precision: 0.710\n",
            "Recall: 1.000\n",
            "F1 Score: 0.830\n",
            "*************************KNeighborsClassifier***************\n",
            "[[36  8]\n",
            " [12  6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.75      0.82      0.78        44\n",
            "           2       0.43      0.33      0.38        18\n",
            "\n",
            "    accuracy                           0.68        62\n",
            "   macro avg       0.59      0.58      0.58        62\n",
            "weighted avg       0.66      0.68      0.66        62\n",
            "\n",
            "Accuracy: 0.677\n",
            "Precision: 0.750\n",
            "Recall: 0.818\n",
            "F1 Score: 0.783\n",
            "*********************MLPClassifier*******************\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[39  5]\n",
            " [15  3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.72      0.89      0.80        44\n",
            "           2       0.38      0.17      0.23        18\n",
            "\n",
            "    accuracy                           0.68        62\n",
            "   macro avg       0.55      0.53      0.51        62\n",
            "weighted avg       0.62      0.68      0.63        62\n",
            "\n",
            "Accuracy: 0.677\n",
            "Precision: 0.722\n",
            "Recall: 0.886\n",
            "F1 Score: 0.796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score, accuracy_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = \"Haber-man.csv\"  # <-- change this to your file\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Separate features and target\n",
        "target = df['Class']\n",
        "df = df.drop(columns=['Class'])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize data\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "# ************************* SVM *************************\n",
        "print(\"*************************SVM (Linear)************************************\")\n",
        "svc = SVC(kernel='linear', C=10.0, random_state=1)\n",
        "svc.fit(X_train_std, y_train)\n",
        "y_pred_svm = svc.predict(X_test_std)\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred_svm))\n",
        "print('Precision: %.3f' % precision_score(y_test, y_pred_svm))\n",
        "print('Recall: %.3f' % recall_score(y_test, y_pred_svm))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, y_pred_svm))\n",
        "\n",
        "\n",
        "# ************************* MultinomialNB *************************\n",
        "print(\"*************************MultinomialNB************************************\")\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train_std, y_train)\n",
        "y_pred_nb = nb.predict(X_test_std)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred_nb))\n",
        "print('Precision: %.3f' % precision_score(y_test, y_pred_nb))\n",
        "print('Recall: %.3f' % recall_score(y_test, y_pred_nb))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, y_pred_nb))\n",
        "\n",
        "\n",
        "# ************************* Decision Tree *************************\n",
        "print(\"***************************DecisionTreeClassifier*********************\")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train_std, y_train)\n",
        "y_predict_DT = clf.predict(X_test_std)\n",
        "print(confusion_matrix(y_test, y_predict_DT))\n",
        "print(classification_report(y_test, y_predict_DT))\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_predict_DT))\n",
        "print('Precision: %.3f' % precision_score(y_test, y_predict_DT))\n",
        "print('Recall: %.3f' % recall_score(y_test, y_predict_DT))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, y_predict_DT))\n",
        "\n",
        "\n",
        "# ************************* Linear Regression *************************\n",
        "print(\"**********************LinearRegression*********************\")\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train_std, y_train)\n",
        "y_predict_LR = reg.predict(X_test_std)\n",
        "\n",
        "# Convert regression output to class labels (rounding)\n",
        "y_predict_LR = (y_predict_LR >= 0.5).astype(int)\n",
        "\n",
        "print(confusion_matrix(y_test, y_predict_LR))\n",
        "print(classification_report(y_test, y_predict_LR))\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_predict_LR))\n",
        "print('Precision: %.3f' % precision_score(y_test, y_predict_LR))\n",
        "print('Recall: %.3f' % recall_score(y_test, y_predict_LR))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, y_predict_LR))\n",
        "\n",
        "\n",
        "# ************************* KNeighborsClassifier *************************\n",
        "print(\"*************************KNeighborsClassifier***************\")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train_std, y_train)\n",
        "y_predict_KNN = neigh.predict(X_test_std)\n",
        "print(confusion_matrix(y_test, y_predict_KNN))\n",
        "print(classification_report(y_test, y_predict_KNN))\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_predict_KNN))\n",
        "print('Precision: %.3f' % precision_score(y_test, y_predict_KNN))\n",
        "print('Recall: %.3f' % recall_score(y_test, y_predict_KNN))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, y_predict_KNN))\n",
        "\n",
        "# ************************* MLPClassifier *************************\n",
        "print(\"*********************MLPClassifier*******************\")\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "clf1 = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf1.fit(X_train_std, y_train)\n",
        "y_predict_MLP = clf1.predict(X_test_std)\n",
        "print(confusion_matrix(y_test, y_predict_MLP))\n",
        "print(classification_report(y_test, y_predict_MLP))\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_predict_MLP))\n",
        "print('Precision: %.3f' % precision_score(y_test, y_predict_MLP))\n",
        "print('Recall: %.3f' % recall_score(y_test, y_predict_MLP))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, y_predict_MLP))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSJUAuatVg12"
      },
      "source": [
        "Exectution time of KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQZm5WgBVfj2",
        "outputId": "e2ff95be-d614-4a59-ff92-6b008943d1b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*************************KNeighborsClassifier***************\n",
            "[[36  8]\n",
            " [12  6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.75      0.82      0.78        44\n",
            "           2       0.43      0.33      0.38        18\n",
            "\n",
            "    accuracy                           0.68        62\n",
            "   macro avg       0.59      0.58      0.58        62\n",
            "weighted avg       0.66      0.68      0.66        62\n",
            "\n",
            "Accuracy: 0.677\n",
            "Precision: 0.750\n",
            "Recall: 0.818\n",
            "F1 Score: 0.783\n",
            "Execution Time (seconds): 0.035925865173339844\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score, accuracy_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = \"Haber-man (1).csv\"  # <-- change this to your file\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Separate features and target\n",
        "target = df['Class']\n",
        "df = df.drop(columns=['Class'])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize data\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "# ************************* KNeighborsClassifier *************************\n",
        "print(\"*************************KNeighborsClassifier***************\")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train_std, y_train)\n",
        "y_predict_KNN = neigh.predict(X_test_std)\n",
        "print(confusion_matrix(y_test, y_predict_KNN))\n",
        "print(classification_report(y_test, y_predict_KNN))\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_predict_KNN))\n",
        "print('Precision: %.3f' % precision_score(y_test, y_predict_KNN))\n",
        "print('Recall: %.3f' % recall_score(y_test, y_predict_KNN))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, y_predict_KNN))\n",
        "# acc = compute_accuracy(df, Rule, d=10)\n",
        "end = time.time()\n",
        "\n",
        "print(\"Execution Time (seconds):\", end - start)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fdca310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
